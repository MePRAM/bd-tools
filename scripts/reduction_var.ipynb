{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Imputation of missing values by KNN for numeric columns.\n",
    "- Imputation of missing values by the \"most frequent\" (mode) for categoric variables.  \n",
    "- Elimination of columns with >10% missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def load_clean_dataset(loaded_df, na_perc_limit, columns_to_delete=[]):\n",
    "    print(f\"Shape inicial: {loaded_df.shape}\")\n",
    "\n",
    "    loaded_df = loaded_df.drop(columns=columns_to_delete, errors=\"ignore\")\n",
    "\n",
    "    tot = loaded_df.shape[0]\n",
    "\n",
    "    for col in loaded_df.columns:\n",
    "        na_per = 1 - len(loaded_df[col].dropna()) / tot\n",
    "        if na_per > na_perc_limit:\n",
    "            print(f\"Column {col} --> %NaN = {na_per}. deleted\")\n",
    "            loaded_df = loaded_df.drop(columns=col)\n",
    "\n",
    "\n",
    "    if 'mujer_gestante' in loaded_df.columns:\n",
    "        loaded_df['mujer_gestante'] = (\n",
    "            loaded_df['mujer_gestante']\n",
    "            .map({'False': 0, 'True': 1})  \n",
    "            .fillna(0)  \n",
    "        )\n",
    "\n",
    "    numeric_cols = loaded_df.select_dtypes(include=[\"int\", \"float\"]).columns\n",
    "    categorical_cols = loaded_df.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "    binary_cols = [col for col in numeric_cols if set(loaded_df[col].dropna().unique()) <= {0, 1}]\n",
    "    continuous_cols = [col for col in numeric_cols if col not in binary_cols]\n",
    "    categorical_numeric_cols = [\n",
    "        col for col in continuous_cols if loaded_df[col].nunique() <15\n",
    "    ]\n",
    "    continuous_cols = [col for col in continuous_cols if col not in categorical_numeric_cols]\n",
    "    \n",
    "    if binary_cols:\n",
    "        binary_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "        loaded_df[binary_cols] = binary_imputer.fit_transform(loaded_df[binary_cols]).astype(int)\n",
    "\n",
    "    if continuous_cols:\n",
    "        numeric_imputer = KNNImputer(n_neighbors=5, weights=\"distance\")\n",
    "        loaded_df[continuous_cols] = numeric_imputer.fit_transform(loaded_df[continuous_cols])\n",
    "        loaded_df[continuous_cols] = loaded_df[continuous_cols].round(1)\n",
    "\n",
    "    if len(categorical_cols) > 0:\n",
    "        categorical_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "        loaded_df[categorical_cols] = categorical_imputer.fit_transform(loaded_df[categorical_cols])\n",
    "        loaded_df[categorical_cols] = loaded_df[categorical_cols].astype(int)\n",
    "    \n",
    "    if categorical_numeric_cols:\n",
    "        categorical_numeric_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "        loaded_df[categorical_numeric_cols] = categorical_numeric_imputer.fit_transform(loaded_df[categorical_numeric_cols])\n",
    "        loaded_df[categorical_numeric_cols] = loaded_df[categorical_numeric_cols].astype(int)\n",
    "\n",
    "    print(f\"Shape final: {loaded_df.shape}\")\n",
    "    return loaded_df\n",
    "\n",
    "\n",
    "def combine_columns(df_to_clean, column_list, new_col_name):\n",
    "    df_to_clean[new_col_name] = df_to_clean[column_list].sum(axis=1).astype(int)\n",
    "    clean_df = df_to_clean.drop(columns=column_list)\n",
    "    return clean_df\n",
    "\n",
    "\n",
    "database_file = \"/home/sergio/git/dev/mepram_testing/bd-tools/data/df_sin_antecedentes_v1.csv\" \n",
    "df_to_clean = pd.read_csv(database_file)\n",
    "\n",
    "hepatic_cols = [c for c in df_to_clean.columns if \"hepatopatia\" in c]\n",
    "tumor_cols = [c for c in df_to_clean.columns if \"cancer\" in c]\n",
    "for new_name, col_list in {\"enf_hepaticas\": hepatic_cols, \"tumores\": tumor_cols}.items():\n",
    "    df_to_clean = combine_columns(df_to_clean, col_list, new_name)\n",
    "\n",
    "columns_to_delete = [\"Unnamed: 0\", \"person_id\", \"fecha_ingreso_urgencias\", \"shock_septico\", \"foco\", \"sintoma_nan\", \"fecha_nacimiento\", \"codigo_postal\", \"center\", \"dag\"]\n",
    "processed_df = load_clean_dataset(\n",
    "    loaded_df=df_to_clean,\n",
    "    na_perc_limit=0.1,\n",
    "    columns_to_delete=columns_to_delete\n",
    ")\n",
    "\n",
    "print(\"Pre-processing completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Elimination of variables with variance close to zero.\n",
    "- Elimination of highly correlated variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varianza_cero = processed_df.var() == 0\n",
    "preprocessed_df = processed_df.loc[:, ~varianza_cero]\n",
    "\n",
    "print(f\"Deleted columns: {processed_df.columns[varianza_cero].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df_copy = processed_df\n",
    "\n",
    "target_copy = processed_df_copy[\"sepsis\"]\n",
    "scaler = MinMaxScaler()\n",
    "X_preprocessed = pd.DataFrame(scaler.fit_transform(processed_df_copy.drop(columns=[\"sepsis\"])))\n",
    "X_preprocessed[\"sepsis\"] = target_copy\n",
    "\n",
    "target_palette = {0: \"blue\", 1: \"red\"}\n",
    "row_colors = X_preprocessed[\"sepsis\"].map(target_palette)\n",
    "X_preprocessed = X_preprocessed.dropna() \n",
    "sns.clustermap(\n",
    "    X_preprocessed.drop(columns=[\"sepsis\"]), \n",
    "    cmap=\"coolwarm\",\n",
    "    row_colors=row_colors,  \n",
    "    figsize=(30, 60),\n",
    "    annot=False, \n",
    "    col_cluster=False\n",
    ")\n",
    "\n",
    "plt.title(\"Heatmap con Clustering y Anotaci√≥n por Target\", pad=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA\n",
    "\n",
    "- Scaled data using MinMaxScaler()\n",
    "\n",
    "Plot PCA 2D and 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "target = processed_df['sepsis']\n",
    "data = processed_df.drop(columns= ['sepsis'])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca_data = pca.fit_transform(scaled_data)\n",
    "\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(f\"Varianza explicada por cada componente: {explained_variance}\")\n",
    "print(f\"Varianza total explicada: {sum(explained_variance)}\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(pca_data[:, 0], pca_data[:, 1], c=target, cmap='viridis', alpha=0.7)\n",
    "plt.title(\"PCA 2D\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px \n",
    "\n",
    "pca_3d = PCA(n_components=3)\n",
    "pca_data_3d = pca_3d.fit_transform(scaled_data)\n",
    "\n",
    "pca_df = pd.DataFrame(pca_data_3d, columns=[\"PC1\", \"PC2\" ,\"PC3\"])\n",
    "pca_df[\"sepsis\"] = target\n",
    "\n",
    "fig = px.scatter_3d(\n",
    "    pca_df,\n",
    "    x=\"PC1\",\n",
    "    y=\"PC2\",\n",
    "    z=\"PC3\",\n",
    "    color = \"sepsis\",\n",
    "    title = \"PCA - 3D Visualization\",\n",
    "    labels= {\"sepsis\": \"Sepsis (0=No, 1= Yes)\"},\n",
    "    color_continuous_scale=\"Viridis\", \n",
    "    opacity=0.7  \n",
    ")\n",
    "fig.update_traces(marker=dict(size=5))  \n",
    "fig.update_layout(scene=dict(\n",
    "    xaxis_title=\"PC 1\",\n",
    "    yaxis_title=\"PC 2\",\n",
    "    zaxis_title=\"PC 3\"\n",
    "))\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
