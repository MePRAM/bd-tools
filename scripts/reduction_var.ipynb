{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Imputation of missing values by KNN for numeric columns.\n",
    "- Imputation of missing values by the \"most frequent\" (mode) for categoric variables.  \n",
    "- Elimination of columns with >10% missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def load_clean_dataset(loaded_df, na_perc_limit, columns_to_delete=[]):\n",
    "    print(f\"Shape inicial: {loaded_df.shape}\")\n",
    "\n",
    "    loaded_df = loaded_df.drop(columns=columns_to_delete, errors=\"ignore\")\n",
    "\n",
    "    tot = loaded_df.shape[0]\n",
    "\n",
    "    for col in loaded_df.columns:\n",
    "        na_per = 1 - len(loaded_df[col].dropna()) / tot\n",
    "        if na_per > na_perc_limit:\n",
    "            print(f\"Column {col} --> %NaN = {na_per}. deleted\")\n",
    "            loaded_df = loaded_df.drop(columns=col)\n",
    "\n",
    "\n",
    "    if 'mujer_gestante' in loaded_df.columns:\n",
    "        loaded_df['mujer_gestante'] = (\n",
    "            loaded_df['mujer_gestante']\n",
    "            .map({'False': 0, 'True': 1})  \n",
    "            .fillna(0)  \n",
    "        )\n",
    "\n",
    "    numeric_cols = loaded_df.select_dtypes(include=[\"int\", \"float\"]).columns\n",
    "    categorical_cols = loaded_df.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "    binary_cols = [col for col in numeric_cols if set(loaded_df[col].dropna().unique()) <= {0, 1}]\n",
    "    continuous_cols = [col for col in numeric_cols if col not in binary_cols]\n",
    "    categorical_numeric_cols = [\n",
    "        col for col in continuous_cols if loaded_df[col].nunique() <15\n",
    "    ]\n",
    "    continuous_cols = [col for col in continuous_cols if col not in categorical_numeric_cols]\n",
    "    \n",
    "    if binary_cols:\n",
    "        binary_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "        loaded_df[binary_cols] = binary_imputer.fit_transform(loaded_df[binary_cols]).astype(int)\n",
    "\n",
    "    if continuous_cols:\n",
    "        numeric_imputer = KNNImputer(n_neighbors=5, weights=\"distance\")\n",
    "        loaded_df[continuous_cols] = numeric_imputer.fit_transform(loaded_df[continuous_cols])\n",
    "        loaded_df[continuous_cols] = loaded_df[continuous_cols].round(1)\n",
    "\n",
    "    if len(categorical_cols) > 0:\n",
    "        categorical_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "        loaded_df[categorical_cols] = categorical_imputer.fit_transform(loaded_df[categorical_cols])\n",
    "        loaded_df[categorical_cols] = loaded_df[categorical_cols].astype(int)\n",
    "    \n",
    "    if categorical_numeric_cols:\n",
    "        categorical_numeric_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "        loaded_df[categorical_numeric_cols] = categorical_numeric_imputer.fit_transform(loaded_df[categorical_numeric_cols])\n",
    "        loaded_df[categorical_numeric_cols] = loaded_df[categorical_numeric_cols].astype(int)\n",
    "\n",
    "    print(f\"Shape final: {loaded_df.shape}\")\n",
    "    return loaded_df\n",
    "\n",
    "\n",
    "def combine_columns(df_to_clean, column_list, new_col_name):\n",
    "    df_to_clean[new_col_name] = df_to_clean[column_list].sum(axis=1).astype(int)\n",
    "    clean_df = df_to_clean.drop(columns=column_list)\n",
    "    return clean_df\n",
    "\n",
    "\n",
    "database_file = \"/home/sergio/git/dev/mepram_testing/bd-tools/data/df_sin_antecedentes_v1.csv\" \n",
    "df_to_clean = pd.read_csv(database_file)\n",
    "\n",
    "hepatic_cols = [c for c in df_to_clean.columns if \"hepatopatia\" in c]\n",
    "tumor_cols = [c for c in df_to_clean.columns if \"cancer\" in c]\n",
    "for new_name, col_list in {\"enf_hepaticas\": hepatic_cols, \"tumores\": tumor_cols}.items():\n",
    "    df_to_clean = combine_columns(df_to_clean, col_list, new_name)\n",
    "\n",
    "columns_to_delete = [\"Unnamed: 0\", \"person_id\", \"fecha_ingreso_urgencias\", \"shock_septico\", \"foco\", \"sintoma_nan\", \"fecha_nacimiento\", \"codigo_postal\", \"center\", \"dag\"]\n",
    "processed_df = load_clean_dataset(\n",
    "    loaded_df=df_to_clean,\n",
    "    na_perc_limit=0.1,\n",
    "    columns_to_delete=columns_to_delete\n",
    ")\n",
    "\n",
    "print(\"Pre-processing completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Elimination of variables with variance close to zero.\n",
    "- Elimination of highly correlated variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varianza_cero = processed_df.var() == 0\n",
    "preprocessed_df = processed_df.loc[:, ~varianza_cero]\n",
    "\n",
    "print(f\"Deleted columns: {processed_df.columns[varianza_cero].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df_copy = processed_df\n",
    "\n",
    "target_copy = processed_df_copy[\"sepsis\"]\n",
    "scaler = MinMaxScaler()\n",
    "X_preprocessed = pd.DataFrame(scaler.fit_transform(processed_df_copy.drop(columns=[\"sepsis\"])))\n",
    "X_preprocessed[\"sepsis\"] = target_copy\n",
    "\n",
    "target_palette = {0: \"blue\", 1: \"red\"}\n",
    "row_colors = X_preprocessed[\"sepsis\"].map(target_palette)\n",
    "X_preprocessed = X_preprocessed.dropna() \n",
    "sns.clustermap(\n",
    "    X_preprocessed.drop(columns=[\"sepsis\"]), \n",
    "    cmap=\"coolwarm\",\n",
    "    row_colors=row_colors,  \n",
    "    figsize=(30, 60),\n",
    "    annot=False, \n",
    "    col_cluster=False\n",
    ")\n",
    "\n",
    "plt.title(\"Heatmap con Clustering y Anotaci√≥n por Target\", pad=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA\n",
    "\n",
    "- Scaled data using MinMaxScaler()\n",
    "\n",
    "Plot PCA 2D and 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "target = processed_df['sepsis']\n",
    "data = processed_df.drop(columns= ['sepsis'])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca_data = pca.fit_transform(scaled_data)\n",
    "\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(f\"Varianza explicada por cada componente: {explained_variance}\")\n",
    "print(f\"Varianza total explicada: {sum(explained_variance)}\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(pca_data[:, 0], pca_data[:, 1], c=target, cmap='viridis', alpha=0.7)\n",
    "plt.title(\"PCA 2D\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px \n",
    "\n",
    "pca_3d = PCA(n_components=3)\n",
    "pca_data_3d = pca_3d.fit_transform(scaled_data)\n",
    "\n",
    "pca_df = pd.DataFrame(pca_data_3d, columns=[\"PC1\", \"PC2\" ,\"PC3\"])\n",
    "pca_df[\"sepsis\"] = target\n",
    "\n",
    "fig = px.scatter_3d(\n",
    "    pca_df,\n",
    "    x=\"PC1\",\n",
    "    y=\"PC2\",\n",
    "    z=\"PC3\",\n",
    "    color = \"sepsis\",\n",
    "    title = \"PCA - 3D Visualization\",\n",
    "    labels= {\"sepsis\": \"Sepsis (0=No, 1= Yes)\"},\n",
    "    color_continuous_scale=\"Viridis\", \n",
    "    opacity=0.7  \n",
    ")\n",
    "fig.update_traces(marker=dict(size=5))  \n",
    "fig.update_layout(scene=dict(\n",
    "    xaxis_title=\"PC 1\",\n",
    "    yaxis_title=\"PC 2\",\n",
    "    zaxis_title=\"PC 3\"\n",
    "))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recursive Feature Elimination\n",
    "\n",
    "- Random forest\n",
    "- SVM\n",
    "- Logistic Regression\n",
    "- Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, f1_score, precision_recall_curve, average_precision_score\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "X = processed_df.drop(columns=[\"sepsis\"])\n",
    "y = processed_df[\"sepsis\"].astype(int)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=99)\n",
    "\n",
    "X_train = pd.DataFrame(X_train, columns=X.columns).reset_index(drop=True)\n",
    "X_test = pd.DataFrame(X_test, columns=X.columns).reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=99),\n",
    "    \"SVM\": SVC(kernel=\"linear\", probability=True, random_state=99),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=99),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=99),\n",
    "}\n",
    "\n",
    "results_all_vars = {}\n",
    "results = {}\n",
    "important_features = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    \n",
    "    print(f\"\\nModelo: {name}\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_prob_test = model.predict_proba(X_test)[:, 1]\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "    fpr_test, tpr_test, _ = roc_curve(y_test, y_pred_prob_test)\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred_prob_test)\n",
    "    auc_test = auc(fpr_test, tpr_test)\n",
    "    avg_precision = average_precision_score(y_test, y_pred_prob_test)\n",
    "    f1_test = f1_score(y_test, y_pred_test)\n",
    "    \n",
    "    results_all_vars[name] = {\n",
    "        \"fpr_test\": fpr_test,\n",
    "        \"tpr_test\": tpr_test,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"auc_test\": auc_test,\n",
    "        \"avg_precision\": avg_precision,\n",
    "        \"f1_test\": f1_test,\n",
    "    }\n",
    "\n",
    "    print(f\"AUC (all features): {auc_test:.3f}, Avg Precision: {avg_precision:.3f}, F1: {f1_test:.3f}\")\n",
    "    \n",
    "    print(f\"\\Training {name} with RFECV ...\")\n",
    "\n",
    "    auc_test_scores = []\n",
    "    f1_test_scores = []\n",
    "\n",
    "    rfe = RFECV(estimator=model,\n",
    "                step=1,\n",
    "                cv=StratifiedKFold(n_splits=10),\n",
    "                scoring=\"f1\")\n",
    "    \n",
    "    rfe.fit(X_train, y_train)\n",
    "\n",
    "    print(f\"Optimum number of characteristics for {name}: {rfe.n_features_}\")\n",
    "    \n",
    "    final_features = X_train.columns[rfe.support_]\n",
    "    important_features[name] = final_features\n",
    "\n",
    "    X_train_rfe = X_train[final_features]\n",
    "    X_test_rfe = X_test[final_features]\n",
    "\n",
    "    model.fit(X_train_rfe, y_train)\n",
    "\n",
    "    y_pred_prob_test = model.predict_proba(X_test_rfe)[:, 1]\n",
    "    y_pred_test = model.predict(X_test_rfe)\n",
    "\n",
    "    fpr_test, tpr_test, _ = roc_curve(y_test, y_pred_prob_test)\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred_prob_test)\n",
    "    auc_test = auc(fpr_test, tpr_test)\n",
    "    avg_precision = average_precision_score(y_test, y_pred_prob_test)\n",
    "    f1_test = f1_score(y_test, y_pred_test)\n",
    "\n",
    "    results[name] = {\n",
    "        \"fpr_test\": fpr_test,\n",
    "        \"tpr_test\": tpr_test,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"auc_test\": auc_test,\n",
    "        \"avg_precision\": avg_precision,\n",
    "        \"f1_test\": f1_test,\n",
    "        \"selected_features\": final_features,\n",
    "    }\n",
    "\n",
    "    print(f\"{name} - AUC Test: {auc_test:.3f}, F1 Test: {f1_test:.3f}\")\n",
    "    print(f\"Caracter√≠sticas seleccionadas por {name}: {final_features}\")\n",
    "\n",
    "# ROC\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "for model_name in results_all_vars:\n",
    "    metrics = results_all_vars[model_name]\n",
    "    plt.plot(metrics[\"fpr_test\"], metrics[\"tpr_test\"], label=f\"{model_name} (AUC: {metrics['auc_test']:.3f})\")\n",
    "plt.plot([0, 1], [0, 1], \"k--\", label=\"Random (AUC: 0.500)\")\n",
    "plt.title(\"Comparison of models by ROC curves (all features)\")\n",
    "plt.xlabel(\"1 - Specificity\")\n",
    "plt.ylabel(\"Sensitivity\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "for model_name, metrics in results.items():\n",
    "    plt.plot(metrics[\"fpr_test\"], metrics[\"tpr_test\"], label=f\"{model_name} (AUC: {metrics['auc_test']:.3f})\")\n",
    "plt.plot([0, 1], [0, 1], \"k--\", label=\"Random (AUC: 0.500)\")\n",
    "plt.title(\"Comparison of models by ROC curves\")\n",
    "plt.xlabel(\"1 - Specificity\")\n",
    "plt.ylabel(\"Sensitivity\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# RECALL\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "for model_name, metrics in results_all_vars.items():\n",
    "    plt.plot(metrics[\"recall\"], metrics[\"precision\"], label=f\"{model_name} (Avg Precision: {metrics['avg_precision']:.3f})\")\n",
    "plt.axhline(y=0.5, color=\"r\", linestyle=\"--\", label=\"Precisi√≥n = 0.500\")\n",
    "plt.title(\"Precision-Recall - All features\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "for model_name, metrics in results.items():\n",
    "    plt.plot(metrics[\"recall\"], metrics[\"precision\"], label=f\"{model_name} (Avg Precision: {metrics['avg_precision']:.3f})\")\n",
    "plt.axhline(y=0.5, color=\"r\", linestyle=\"--\", label=\"Precisi√≥n = 0.500\")\n",
    "plt.title(\"Precision-Recall - Selected features\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, len(important_features), figsize=(20, 8), sharey=True)\n",
    "for ax, (model_name, features) in zip(axes, important_features.items()):\n",
    "    ax.barh(features, range(len(features)))\n",
    "    ax.set_title(model_name)\n",
    "    ax.set_xlabel(\"Importance ranking\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "consensus_features = set(important_features[list(important_features.keys())[0]])\n",
    "for features in important_features.values():\n",
    "    consensus_features &= set(features)\n",
    "\n",
    "print(\"\\nSelected features: \", list(consensus_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selected features\n",
    "- estado_mental_alterado\n",
    "- proteina_c_reactiva\n",
    "- respiracion\n",
    "- frec_cardiaca\n",
    "- creatinina\n",
    "- edad\n",
    "- vasopresores\n",
    "- cardiovascular"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
