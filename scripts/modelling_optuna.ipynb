{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization using Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import (train_test_split, cross_val_score)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    recall_score,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    log_loss,\n",
    "    confusion_matrix,\n",
    "    precision_recall_curve,\n",
    "    auc,\n",
    "    roc_curve\n",
    ")\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clean_dataset(loaded_df, na_perc_limit, columns_to_delete=[]):\n",
    "    tot = loaded_df.shape[0]\n",
    "    loaded_df = loaded_df.drop(columns=columns_to_delete)\n",
    "    for col in loaded_df.columns:\n",
    "        na_per = 1 - len(loaded_df[col].dropna()) / tot\n",
    "        if na_per > na_perc_limit:\n",
    "            loaded_df = loaded_df.drop(columns=col)\n",
    "    loaded_df = loaded_df.dropna()\n",
    "    return loaded_df\n",
    "\n",
    "def combine_columns(df_to_clean, column_list, new_col_name):\n",
    "    df_to_clean[new_col_name] = df_to_clean[column_list].sum(axis=1).astype(int)\n",
    "    clean_df = df_to_clean.drop(columns=column_list)\n",
    "    return clean_df\n",
    "\n",
    "def preprocess_data(database_file):\n",
    "    columns_to_delete = [\n",
    "        \"Unnamed: 0\", \"person_id\", \"fecha_ingreso_urgencias\", \"shock_septico\", \n",
    "        \"foco\", \"sintoma_nan\", \"fecha_nacimiento\", \"codigo_postal\", \"center\", \"dag\"\n",
    "    ]\n",
    "    df_to_clean = pd.read_csv(database_file)\n",
    "    hepatic_cols = [c for c in df_to_clean.columns if \"hepatopatia\" in c]\n",
    "    tumor_cols = [c for c in df_to_clean.columns if \"cancer\" in c]\n",
    "    for new_name, col_list in {\"enf_hepaticas\": hepatic_cols, \"tumores\": tumor_cols}.items():\n",
    "        df_to_clean = combine_columns(df_to_clean, col_list, new_name)\n",
    "    processed_df = load_clean_dataset(\n",
    "        loaded_df=df_to_clean,\n",
    "        na_perc_limit=0.1,\n",
    "        columns_to_delete=columns_to_delete\n",
    "    )\n",
    "    return processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_random_forest(trial, X_train, y_train, X_val, y_val):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "        'bootstrap': trial.suggest_categorical('bootstrap', [True, False])\n",
    "    }\n",
    "    model = RandomForestClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    logloss = log_loss(y_val, model.predict_proba(X_val))\n",
    "    return f1, logloss\n",
    "\n",
    "def objective_xgboost(trial, X_train, y_train, X_val, y_val):\n",
    "    params = {\n",
    "        'verbosity': 0,\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'auc',\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 400),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 0.5),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.01, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.01, 10.0, log=True),\n",
    "        'scale_pos_weight': trial.suggest_int('scale_pos_weight', 1, 10)\n",
    "    }\n",
    "    model = XGBClassifier(**params)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "    y_pred = model.predict(X_val)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    logloss = log_loss(y_val, model.predict_proba(X_val))\n",
    "    return f1, logloss\n",
    "\n",
    "def objective_svm(trial, X_train, y_train, X_val, y_val):\n",
    "    params = {\n",
    "        'C': trial.suggest_float('C', 0.1, 10.0),\n",
    "        'kernel': trial.suggest_categorical('kernel', ['linear', 'rbf', 'poly']),\n",
    "        'gamma': trial.suggest_float('gamma', 0.001, 1.0)\n",
    "    }\n",
    "    model = SVC(**params, probability=True)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    logloss = log_loss(y_val, model.predict_proba(X_val))\n",
    "    return f1, logloss\n",
    "\n",
    "def evaluate_models(models, X_test, y_test):\n",
    "    results = []\n",
    "    for model_name, model in models.items():\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "        metrics = {\n",
    "            'Model': model_name,\n",
    "            'F1': f1_score(y_test, y_pred),\n",
    "            'Recall': recall_score(y_test, y_pred),\n",
    "            'Accuracy': accuracy_score(y_test, y_pred),\n",
    "            'Precision': precision_score(y_test, y_pred),\n",
    "            'ROC AUC': roc_auc_score(y_test, y_pred_prob) if y_pred_prob is not None else 'N/A'\n",
    "        }\n",
    "        print(f\"\\nClassification Report for {model_name}:\\n\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        results.append(metrics)\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def plot_optuna_metrics(rf_study, xgb_study, svm_study):\n",
    "    studies = {\n",
    "        \"Random Forest\": rf_study,\n",
    "        \"XGBoost\": xgb_study,\n",
    "        \"SVM\": svm_study\n",
    "    }\n",
    "\n",
    "    # Plot F1 Score\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for model_name, study in studies.items():\n",
    "        trials_f1 = [trial.values[0] for trial in study.trials if trial.state == optuna.trial.TrialState.COMPLETE]\n",
    "        plt.plot(range(1, len(trials_f1) + 1), trials_f1, label=f\"{model_name} - F1\")\n",
    "\n",
    "    plt.title(\"F1-Score Evolution Across Trials\")\n",
    "    plt.xlabel(\"Trial\")\n",
    "    plt.ylabel(\"F1-Score\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Plot LogLoss\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for model_name, study in studies.items():\n",
    "        trials_logloss = [trial.values[1] for trial in study.trials if trial.state == optuna.trial.TrialState.COMPLETE]\n",
    "        plt.plot(range(1, len(trials_logloss) + 1), trials_logloss, label=f\"{model_name} - LogLoss\")\n",
    "\n",
    "    plt.title(\"LogLoss Evolution Across Trials\")\n",
    "    plt.xlabel(\"Trial\")\n",
    "    plt.ylabel(\"LogLoss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_metrics(models, X_test, y_test):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # ROC Curve\n",
    "    plt.subplot(1, 3, 1)\n",
    "    for model_name, model in models.items():\n",
    "        y_pred_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "        if y_pred_prob is not None:\n",
    "            fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            plt.plot(fpr, tpr, label=f\"{model_name} (AUC = {roc_auc:.2f})\")\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.title(\"ROC Curve\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Recall-Precision Curve\n",
    "    plt.subplot(1, 3, 2)\n",
    "    for model_name, model in models.items():\n",
    "        y_pred_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "        if y_pred_prob is not None:\n",
    "            precision, recall, _ = precision_recall_curve(y_test, y_pred_prob)\n",
    "            plt.plot(recall, precision, label=f\"{model_name}\")\n",
    "    plt.title(\"Precision-Recall Curve\")\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Confusion Matrix\n",
    "    for model_name, model in models.items():\n",
    "        y_pred = model.predict(X_test)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"No Sepsis\", \"Sepsis\"], yticklabels=[\"No Sepsis\", \"Sepsis\"])\n",
    "        plt.title(f\"Confusion Matrix for {model_name}\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    database_file = \"/home/sergio/git/dev/mepram_testing/bd-tools/data/df_sin_antecedentes_v1.csv\"\n",
    "    output_location = \"/home/sergio/git/dev/mepram_testing/bd-tools/output_testing/\"\n",
    "\n",
    "    processed_df = preprocess_data(database_file)\n",
    "    processed_df = processed_df.drop(columns=['mujer_gestante'])\n",
    "    X = processed_df.drop(\"sepsis\", axis=1)\n",
    "    y = processed_df[\"sepsis\"]\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=99)\n",
    "\n",
    "    rf_study = optuna.create_study(directions=[\"maximize\", \"minimize\"])\n",
    "    rf_study.optimize(lambda trial: objective_random_forest(trial, X_train, y_train, X_test, y_test), n_trials=250)\n",
    "    best_rf_params = rf_study.best_trials[0].params\n",
    "    best_rf_model = RandomForestClassifier(**best_rf_params).fit(X_train, y_train)\n",
    "\n",
    "    xgb_study = optuna.create_study(directions=[\"maximize\", \"minimize\"])\n",
    "    xgb_study.optimize(lambda trial: objective_xgboost(trial, X_train, y_train, X_test, y_test), n_trials=250)\n",
    "    best_xgb_params = xgb_study.best_trials[0].params\n",
    "    best_xgb_model = XGBClassifier(**best_xgb_params).fit(X_train, y_train)\n",
    "\n",
    "    svm_study = optuna.create_study(directions=[\"maximize\", \"minimize\"])\n",
    "    svm_study.optimize(lambda trial: objective_svm(trial, X_train, y_train, X_test, y_test), n_trials=250)\n",
    "    best_svm_params = svm_study.best_trials[0].params\n",
    "    best_svm_model = SVC(**best_svm_params, probability=True).fit(X_train, y_train)\n",
    "\n",
    "    models = {\n",
    "        \"Random Forest\": best_rf_model,\n",
    "        \"XGBoost\": best_xgb_model,\n",
    "        \"SVM\": best_svm_model\n",
    "    }\n",
    "    results = evaluate_models(models, X_test, y_test)\n",
    "\n",
    "    print(\"Model Comparison:\\n\", results)\n",
    "    results.to_csv(os.path.join(output_location, \"model_comparison.csv\"), index=False)\n",
    "\n",
    "    # Plot metrics\n",
    "    plot_optuna_metrics(rf_study, xgb_study, svm_study)\n",
    "    \n",
    "    plot_metrics(models, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impute missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def load_clean_dataset_impute(loaded_df, na_perc_limit, columns_to_delete=[]):\n",
    "    print(f\"Shape inicial: {loaded_df.shape}\")\n",
    "\n",
    "    loaded_df = loaded_df.drop(columns=columns_to_delete, errors=\"ignore\")\n",
    "\n",
    "    tot = loaded_df.shape[0]\n",
    "\n",
    "    for col in loaded_df.columns:\n",
    "        na_per = 1 - len(loaded_df[col].dropna()) / tot\n",
    "        if na_per > na_perc_limit:\n",
    "            print(f\"Column {col} --> %NaN = {na_per}. deleted\")\n",
    "            loaded_df = loaded_df.drop(columns=col)\n",
    "\n",
    "\n",
    "    if 'mujer_gestante' in loaded_df.columns:\n",
    "        loaded_df['mujer_gestante'] = (\n",
    "            loaded_df['mujer_gestante']\n",
    "            .map({'False': 0, 'True': 1})  \n",
    "            .fillna(0)  \n",
    "        )\n",
    "\n",
    "    numeric_cols = loaded_df.select_dtypes(include=[\"int\", \"float\"]).columns\n",
    "    categorical_cols = loaded_df.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "    binary_cols = [col for col in numeric_cols if set(loaded_df[col].dropna().unique()) <= {0, 1}]\n",
    "    continuous_cols = [col for col in numeric_cols if col not in binary_cols]\n",
    "    categorical_numeric_cols = [\n",
    "        col for col in continuous_cols if loaded_df[col].nunique() <15\n",
    "    ]\n",
    "    continuous_cols = [col for col in continuous_cols if col not in categorical_numeric_cols]\n",
    "    \n",
    "    if binary_cols:\n",
    "        binary_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "        loaded_df[binary_cols] = binary_imputer.fit_transform(loaded_df[binary_cols]).astype(int)\n",
    "\n",
    "    if continuous_cols:\n",
    "        numeric_imputer = KNNImputer(n_neighbors=5, weights=\"distance\")\n",
    "        loaded_df[continuous_cols] = numeric_imputer.fit_transform(loaded_df[continuous_cols])\n",
    "        loaded_df[continuous_cols] = loaded_df[continuous_cols].round(1)\n",
    "\n",
    "    if len(categorical_cols) > 0:\n",
    "        categorical_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "        loaded_df[categorical_cols] = categorical_imputer.fit_transform(loaded_df[categorical_cols])\n",
    "        loaded_df[categorical_cols] = loaded_df[categorical_cols].astype(int)\n",
    "    \n",
    "    if categorical_numeric_cols:\n",
    "        categorical_numeric_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "        loaded_df[categorical_numeric_cols] = categorical_numeric_imputer.fit_transform(loaded_df[categorical_numeric_cols])\n",
    "        loaded_df[categorical_numeric_cols] = loaded_df[categorical_numeric_cols].astype(int)\n",
    "\n",
    "    print(f\"Shape final: {loaded_df.shape}\")\n",
    "    return loaded_df\n",
    "\n",
    "\n",
    "def combine_columns(df_to_clean, column_list, new_col_name):\n",
    "    df_to_clean[new_col_name] = df_to_clean[column_list].sum(axis=1).astype(int)\n",
    "    clean_df = df_to_clean.drop(columns=column_list)\n",
    "    return clean_df\n",
    "\n",
    "\n",
    "database_file = \"/home/sergio/git/dev/mepram_testing/bd-tools/data/df_sin_antecedentes_v1.csv\" \n",
    "df_to_clean = pd.read_csv(database_file)\n",
    "\n",
    "hepatic_cols = [c for c in df_to_clean.columns if \"hepatopatia\" in c]\n",
    "tumor_cols = [c for c in df_to_clean.columns if \"cancer\" in c]\n",
    "for new_name, col_list in {\"enf_hepaticas\": hepatic_cols, \"tumores\": tumor_cols}.items():\n",
    "    df_to_clean = combine_columns(df_to_clean, col_list, new_name)\n",
    "\n",
    "columns_to_delete = [\"Unnamed: 0\", \"person_id\", \"fecha_ingreso_urgencias\", \"shock_septico\", \"foco\", \"sintoma_nan\", \"fecha_nacimiento\", \"codigo_postal\", \"center\", \"dag\"]\n",
    "processed_df = load_clean_dataset_impute(\n",
    "    loaded_df=df_to_clean,\n",
    "    na_perc_limit=0.1,\n",
    "    columns_to_delete=columns_to_delete\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
