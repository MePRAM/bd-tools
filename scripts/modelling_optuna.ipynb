{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization using Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import (train_test_split, cross_val_score)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    recall_score,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    log_loss,\n",
    "    confusion_matrix,\n",
    "    precision_recall_curve,\n",
    "    auc,\n",
    "    roc_curve\n",
    ")\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clean_dataset(loaded_df, na_perc_limit, columns_to_delete=[]):\n",
    "    tot = loaded_df.shape[0]\n",
    "    loaded_df = loaded_df.drop(columns=columns_to_delete)\n",
    "    for col in loaded_df.columns:\n",
    "        na_per = 1 - len(loaded_df[col].dropna()) / tot\n",
    "        if na_per > na_perc_limit:\n",
    "            loaded_df = loaded_df.drop(columns=col)\n",
    "    loaded_df = loaded_df.dropna()\n",
    "    return loaded_df\n",
    "\n",
    "def combine_columns(df_to_clean, column_list, new_col_name):\n",
    "    df_to_clean[new_col_name] = df_to_clean[column_list].sum(axis=1).astype(int)\n",
    "    clean_df = df_to_clean.drop(columns=column_list)\n",
    "    return clean_df\n",
    "\n",
    "def preprocess_data(database_file):\n",
    "    columns_to_delete = [\n",
    "        \"Unnamed: 0\", \"person_id\", \"fecha_ingreso_urgencias\", \"shock_septico\", \n",
    "        \"foco\", \"sintoma_nan\", \"fecha_nacimiento\", \"codigo_postal\", \"center\", \"dag\"\n",
    "    ]\n",
    "    df_to_clean = pd.read_csv(database_file)\n",
    "    hepatic_cols = [c for c in df_to_clean.columns if \"hepatopatia\" in c]\n",
    "    tumor_cols = [c for c in df_to_clean.columns if \"cancer\" in c]\n",
    "    for new_name, col_list in {\"enf_hepaticas\": hepatic_cols, \"tumores\": tumor_cols}.items():\n",
    "        df_to_clean = combine_columns(df_to_clean, col_list, new_name)\n",
    "    processed_df = load_clean_dataset(\n",
    "        loaded_df=df_to_clean,\n",
    "        na_perc_limit=0.1,\n",
    "        columns_to_delete=columns_to_delete\n",
    "    )\n",
    "    return processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_random_forest(trial, X_train, y_train, X_val, y_val):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "        'bootstrap': trial.suggest_categorical('bootstrap', [True, False])\n",
    "    }\n",
    "    model = RandomForestClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    logloss = log_loss(y_val, model.predict_proba(X_val))\n",
    "    return f1, logloss\n",
    "\n",
    "def objective_xgboost(trial, X_train, y_train, X_val, y_val):\n",
    "    params = {\n",
    "        'verbosity': 0,\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'auc',\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 400),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 0.5),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.01, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.01, 10.0, log=True),\n",
    "        'scale_pos_weight': trial.suggest_int('scale_pos_weight', 1, 10)\n",
    "    }\n",
    "    model = XGBClassifier(**params)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "    y_pred = model.predict(X_val)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    logloss = log_loss(y_val, model.predict_proba(X_val))\n",
    "    return f1, logloss\n",
    "\n",
    "def objective_svm(trial, X_train, y_train, X_val, y_val):\n",
    "    params = {\n",
    "        'C': trial.suggest_float('C', 0.1, 10.0),\n",
    "        'kernel': trial.suggest_categorical('kernel', ['linear', 'rbf', 'poly']),\n",
    "        'gamma': trial.suggest_float('gamma', 0.001, 1.0)\n",
    "    }\n",
    "    model = SVC(**params, probability=True)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    logloss = log_loss(y_val, model.predict_proba(X_val))\n",
    "    return f1, logloss\n",
    "\n",
    "def evaluate_models(models, X_test, y_test):\n",
    "    results = []\n",
    "    for model_name, model in models.items():\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "        metrics = {\n",
    "            'Model': model_name,\n",
    "            'F1': f1_score(y_test, y_pred),\n",
    "            'Recall': recall_score(y_test, y_pred),\n",
    "            'Accuracy': accuracy_score(y_test, y_pred),\n",
    "            'Precision': precision_score(y_test, y_pred),\n",
    "            'ROC AUC': roc_auc_score(y_test, y_pred_prob) if y_pred_prob is not None else 'N/A'\n",
    "        }\n",
    "        print(f\"\\nClassification Report for {model_name}:\\n\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        results.append(metrics)\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def plot_optuna_metrics(rf_study, xgb_study, svm_study):\n",
    "    studies = {\n",
    "        \"Random Forest\": rf_study,\n",
    "        \"XGBoost\": xgb_study,\n",
    "        \"SVM\": svm_study\n",
    "    }\n",
    "\n",
    "    # Plot F1 Score\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for model_name, study in studies.items():\n",
    "        trials_f1 = [trial.values[0] for trial in study.trials if trial.state == optuna.trial.TrialState.COMPLETE]\n",
    "        plt.plot(range(1, len(trials_f1) + 1), trials_f1, label=f\"{model_name} - F1\")\n",
    "\n",
    "    plt.title(\"F1-Score Evolution Across Trials\")\n",
    "    plt.xlabel(\"Trial\")\n",
    "    plt.ylabel(\"F1-Score\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Plot LogLoss\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for model_name, study in studies.items():\n",
    "        trials_logloss = [trial.values[1] for trial in study.trials if trial.state == optuna.trial.TrialState.COMPLETE]\n",
    "        plt.plot(range(1, len(trials_logloss) + 1), trials_logloss, label=f\"{model_name} - LogLoss\")\n",
    "\n",
    "    plt.title(\"LogLoss Evolution Across Trials\")\n",
    "    plt.xlabel(\"Trial\")\n",
    "    plt.ylabel(\"LogLoss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_metrics(models, X_test, y_test):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # ROC Curve\n",
    "    plt.subplot(1, 3, 1)\n",
    "    for model_name, model in models.items():\n",
    "        y_pred_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "        if y_pred_prob is not None:\n",
    "            fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            plt.plot(fpr, tpr, label=f\"{model_name} (AUC = {roc_auc:.2f})\")\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.title(\"ROC Curve\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Recall-Precision Curve\n",
    "    plt.subplot(1, 3, 2)\n",
    "    for model_name, model in models.items():\n",
    "        y_pred_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "        if y_pred_prob is not None:\n",
    "            precision, recall, _ = precision_recall_curve(y_test, y_pred_prob)\n",
    "            plt.plot(recall, precision, label=f\"{model_name}\")\n",
    "    plt.title(\"Precision-Recall Curve\")\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Confusion Matrix\n",
    "    for model_name, model in models.items():\n",
    "        y_pred = model.predict(X_test)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"No Sepsis\", \"Sepsis\"], yticklabels=[\"No Sepsis\", \"Sepsis\"])\n",
    "        plt.title(f\"Confusion Matrix for {model_name}\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
